---
layout:     post
title:      kafka设计——官方文档翻译
date:       2017-12-06
author:     hsd
header-img: img/post-bg-os-metro.jpg
catalog: true
tags:
    - 消息中间件
    - 后台框架
---
>kafka官方文档设计部分的翻译，持续更新中

# 4.设计
## 4.1 动机

我们设计kafka使其成为一个能够处理大公司产生的所有实时数据的统一平台，为了做到这点我们不得不考虑相当广泛的使用场景，它需要有高吞吐量来支撑大量的事件流比如实时日志聚合，它得优雅地处理大量的数据backlog（日志？）来支撑周期性地离线系统数据导入，同时意味着系统不得不有低延迟消息交付，来应对更加传统的消息使用场景.

We wanted to support partitioned, distributed, real-time processing of these feeds to create new, derived feeds. This motivated our partitioning and consumer model.（中间那个feed不是特别理解）

最后在流被送入其他数据系统时，我们知道系统不得不在机器宕机的情况下保证容错

支持这些使用场景将我们指引到一种设计，即有一堆唯一的元素（unique elements)，相比传统消息系统而言更像是数据库日志。我们会在接下来的部分概述下设计中的一些元素
## 4.2 持久化
### 不要害怕文件系统
Kafka严重地依赖文件系统来存储和缓存消息，人们通常认为硬盘是缓慢的，这使得人们怀疑一个持久化的结构是否能提供一个有竞争力的性能。实际上磁盘比人们想象中要更慢、更快，取决于他们怎么使用，同时一个经过恰当设计的磁盘结构通常能和网络一样快

关于磁盘性能很重要的一个事实就是硬盘的吞吐量。结果就是，顺序写一个7200rpm SATA RAID-5 array的JBOD的速度大概是600MB/sec但是随机写只有大约100k/sec，差了超过6000倍...这些顺序读写是所有使用模式中最可预见的，同时被操作系统大量优化过。一个现代的操作系统提供预读和延迟写(write-behind)技术，即读取多个大块数据，将小的逻辑写合并到大的物理写。关于这个话题更深入的讨论可以在[ACM Queue article](http://queue.acm.org/detail.cfm?id=1563874)中找到，他们实际发现[顺序磁盘访问在某些情况下比随机内存访问要快!](http://deliveryimages.acm.org/10.1145/1570000/1563874/jacobs3.jpg)

为了弥补这种性能差异，现代操作系统对使用主存做磁盘缓存变得越发激进，一个现代的操作系统会很乐意将所有的空闲内存用来做磁盘缓存，在内存被回收时会有一点性能惩罚。所有的磁盘读写会通过这个统一的cache进行。除非使用直接IO，否则不容易关闭这个特性，因此即使一个进程维护了一个进程内的数据缓存，这些数据很有可能会与OS的页缓存冗余，实际上将所有的都存储了两次。

此外，我们构建于JVM之上，在java内存使用上花过点时间的人都知道两件事：
1. 对象的内存开销是很大的，通常是实际数据大小的两倍（或更糟糕）
2. java gc变得越发缓慢和精巧（fiddly）随着堆数据的增加

鉴于这些因素，使用文件系统并依赖页缓存优于维护一个内存缓存或者其他结构——我们至少获得了两倍的可用缓存，通过自动访问所有空闲内存（译注：OS页缓存），同时很可能再次加倍通过存储压缩的字节结构而不是独立的对象。这样做使得在一个32GB的机器上cache能达到28-30GB并且没有GC惩罚。进一步，即使服务重启了，这些缓存依然会保持热的状态（stay warm，即热缓存），而进程内缓存需要在内存上重建（10GB的缓存可能会花费10分钟)或者它会以完全冷的缓存启动（这通常意味着糟糕的初始性能）。这也极大简化了代码，因为所有的用来保持内存和文件系统一致性的逻辑都交给了OS，相比一次性的进程内尝试而言，OS通常能更高效更准确的完成这些事情。如果你的磁盘访问模式偏好于顺序读那么预读技术在每次磁盘访问时都会有效地获取有用的数据

这使得好的设计变得非常简单：不是以维护尽可能多的内存数据然后在我们内存空间不足时将其刷新到文件系统的方式，我们反过来做。所有的数据都立即被写到文件系统中的持久化日志中，实际上这仅仅意味这它被传输到内核的页缓存中。

这种以页缓存为中心的设计风格在这篇关于Varnish的设计的[文章](http://varnish-cache.org/wiki/ArchitectNotes)中有描述（带着一种健康的自大）
### Constant Time Suffices
消息系统中使用的持久化数据结构通常是每个消费者一个队列同时有一个用于保存消息元数据的相关的B树或者其他通用目的的随机访问的数据结构。B树是用处最通用的数据结构，能支持消息系统中各种事务和非事务的语义。磁盘访问一次10ms，每次只能做一个搜寻因此并发性收到了限制。因此虽然只是少量的磁盘访问也会有非常高的开销。因为存储系统混合了非常快的缓存操作和非常缓慢的物理磁盘操作，观察到的树形结构的性能通常随着固定缓存的数据的增加呈超线性关系的——即加倍你的数据会使得访问比两倍还慢

直觉来说在简单读和追加到文件的情况下可以使用一个持久化的队列，这通常是logging的解决方法，这个结构有一个优点那就是所有的操作都是O(1)的并且读不会阻塞写反之亦然。这有个明显的性能优势因为性能完全和数据大小解耦开来——一个服务器能充分利用许多廉价的低转速的1+TB的SATA驱动器，尽管它们的寻址性能比比较差，对于大规模读写来说这些驱动器仍有着可以接受的性能同时有着1/3的价格和3倍的容量

能够访问几乎是不受限的磁盘空间并且没有任何性能惩罚意味着我们能够提供一些消息系统中不常见的特性。比如说，在kafka里，我们在一个相对较长的时间段(比如说一周)内保留消息，而不是它们一被消费我们就删了它们，这给消费者带来了很多灵活性，我们之后将会进行描述。
## 4.3 效率
我们在效率上做了很大的努力，一个我们主要的用例场景就是处理web活动数据，数据量往往很大：每一次网页访问会产生数以十计的写。而且，我们假设一个产生的消息至少会被一个消费者（通常很多）读取，因此我们努力使消息消费变得尽可能的廉价

从搭建和运行许多类似的系统的经验中我们同时发现，效率是高效的多租户操作的关键。如果下流的基础组件服务因应用使用模式的微小变化就轻易地变成瓶颈的话，这样的微小变动通常会带来问题。By being very fast we help ensure that the application will tip-over under load before the infrastructure。对于尝试在中心化集群运行一个支持数十或数百个应用的中心化服务时这显得尤为重要，因为使用模式的改变近乎是每天都会发生的事

我们在前面的章节中讨论了磁盘效率，当消除了不良的磁盘访问模式后，还会造成系统低效的两个通常原因位：太多小io操作，以及过多的字节复制

小io问题通常发生在客户端和服务器之间（译注：网络传输）以及服务器自身的持久化操作

为了避免这个问题，我们的协议围绕着message set的抽象构造，message set将消息自然地组合在一起。这允许网络请求将消息整合再一起，均摊了网络往返的开销，而不是每一次发送一个单一的消息。服务器一次将消息块追加到log中，然后消费者每次读取大的线性块

这个简单的优化带来了数量级的加速，批量使得网络包更大，更大的线性磁盘操作，连续的内存块，等等，所有的这些让kafka可以将猝发的随机消息流转变成流向消费者的线性写

另一个造成低效的是字节复制，在低消息速率的情况下这不是个问题，但在运行负载下影响是很显著的。为了避免这个问题我们使用了一个可以在producer、broker、consumer之间共享的标准的二进制的消息格式（因此数据块可以不用被修改就在它们之间传输）

broker维护的消息日志只是一个文件目录，每一个文件由message set序列填充，message set在producer和consumer之间保留着相同的格式。维护这个通用的格式允许对最重要的操作的优化：对持久化日志块的网络传输。现代的unix操作系统提供了一个高度优化过的代码路径来将数据从pagecache中传输到socket上；在linux上这由sendfile系统调用完成

为了理解sendfile的影响，理解将数据从文件到socket的传输的通用代码路径是很重要的：
1. 操作系统将数据从磁盘读入到内核空间中的pagecache中
2. 应用将数据从内核空间读入到用户空间缓存中
3. 应用将数据写回内核空间中的socket缓存中
4. 操作系统将socket缓存中的数据复制到nic缓存中，nic缓存中的数据将会被发送到网络上

这显然是低效的，需要经过四次copy和两次系统调用。通过使用sendfile，这些re-copying可以被消除，通过让OS直接将数据从页缓存（译注：内核空间中）发送到网络上。因此在这个优化后的路径，只需要最后的复制到nic缓存上

我们预料的一个通用的用例场景就是一个topic上有多个consumer，通过使用上面的zero-copy优化，数据正好复制到页缓存一次然后每次消费都能重用，而不是存储在内存中然后每次读取都复制到用户空间中。这允许消息能以接近网络连接限制的速率消费

pagecache和sendfile的结合意味着在一个大多数消费者都追上的kafka集群上你看不到有读磁盘的活动，因为它们都直接从缓存中提供数据

关于sendfile和java对zero-copy的支持的更多背景知识可以查看这篇[文章](http://www.ibm.com/developerworks/linux/library/j-zerocopy)

## 端到端批量压缩
在一些情况下瓶颈实际上不是CPU也不是磁盘而是网络带宽，对于需要通过广域网在数据中心间发送消息的数据流水线来说这尤为正确。当然，没有来自kafka的支持，用户也总是可以每个消息都进行压缩，但这回导致非常差的压缩率，因为大多数的冗余都是因为同类型消息间的重复（比如json中的字段名称或者web日志中的user&ensp;agents或者相同的字符串）。高效的压缩要求同时压缩多个消息而不是对每个消息都单独进行压缩

kafka通过一个高效的批量格式来支持这个，一批消息可以一起被压缩然后以这种形式发送到服务器上，这批消息会以压缩的格式写入，在log中保持压缩的状态然后只会被消费者解压

Kafka支持gzip、snappy、lz4压缩协议，关于压缩更多的细节可以查看[这里](https://cwiki.apache.org/confluence/display/KAFKA/Compression)

# 4.4 生产者
## 负载均衡
生产者直接将数据发送到partition leader所在的broker上，没有任何中间的路由层，为了帮助生产者做到这个所有的kafka节点都可以回答关于那个服务器活着还有任意时刻一个topic的partions的leaders都在哪些节点上的元数据请求，这让生产者可以恰当地发送它的请求

用户控制消息将会发到哪个分区上，可以是随机的，实现一种随机的负载均衡，也可以由一些有语义的分区函数。我们将有语义的分区接口暴露给用户，用户可以通过指定一个分区的key然后使用这个key来hash到一个分区上（如果需要的话也可以覆盖分区函数）。例如，如果选择的分区的key为user id，那么一个特定用户所有的数据都会被发送到相同的分区上。这反过来允许消费者假定它们的消费都是本地的（make locality assumptions about therir consumption），这种精心设计的分区风格允许本地的敏感的消费者处理

## 异步发送

批量是效率的一大驱动，为了使批量成为可能kafka生产者会尝试在内存中累计数据，然后用一个单一的请求将更大的批次发送出去。batching可以被配置为累积不超过一个固定数量的消息，等待不超过一个固定的时延（比如64k或10ms）。这允许累计更多要发送的字节，以及server上少的更大的io操作，这个缓存是可以被配置的，提供了一个机制来权衡小数量的额外延迟来获得更高的吞吐量

[配置细节](http://kafka.apache.org/documentation.html#producerconfigs)和[生产者api](http://kafka.apache.org/082/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html)可以在此文档的别处找到

# 4.5 消费者

kafka消费者通过发送获取请求到它想消费的分区所在的leader broker上工作，对于每个请求，消费者指定其在log中的offset，然后收到从此位置开始的一整块的日志。消费者因此对消费的位置能有很好的控制，并且如果需要的话可以重置位置来重新消费数据

## push vs pull

我们一开始考虑的一个问题是消费者应该是从brokers上pull数据呢还是broker将数据push到消费者上，在这方面kafka遵循了一个被大多数消息系统所共享，更为传统的设计，即将数据是从生产者push到broker上然后consumer从broker上pull数据。一些以日志为中心的系统，比如[Scribe](http://github.com/facebook/scribe)和[Apache Flume](http://flume.apache.org/)，使用了一个非常不同的基于push的方式，数据是被push到下流的。两种方式都各有其优缺点，然而，基于push的系统难以处理不同的消费者（译注：消费能力不同）因为数据传输速率是由broker控制的。目标通常是让消费者能以最大可能的速率进行消费，不幸的是，在一个push的系统中这意味着当消费的消费速率低于生产的速率时（大体上为DOS攻击），消费者倾向于过载。一个基于pull的系统有着更好的特点，即消费者只是简单地落后了然后当它能够追上时追上。通过一些消费者可以暗示它过载的回退协议，问题可以得到缓和，然而让传输速率能充分利用（但永远不要过度利用）消费者比它看上去的到更棘手。之前的一些使用这种风格构建系统的尝试使得我们投入了更传统的pull模型

基于pull的系统的另外一个有点就是它适用于激进地批量化发送给消费者的数据，一个基于push的系统必须选择是立即发送请求还是累积更多的数据然后稍后在不知道下游消费者是否能立即处理消息的情况下发送。如果调试为低延迟，这回使得为了让传输被缓冲然后每次都发送一个消息，这是浪费的。一个基于pull的设计解决了这个问题，因为消费者总是拉取在它在log中位置以后的所有可用消息（或者到某些配置的最大个数）。因为我们在没有引入不必要的延迟的情况下可以得到优化的batching

简单的基于pull的系统的缺点就是如果broker没有数据那么消费者可能会不停地循环pull，高效地忙等待数据的到达。为了避免这个在我们的pull请求中有一些参数可以让消费者请求阻塞在一个long poll等待知道数据到达（也可选等待直到有给定数据的字节来确保大的传输大小）

你可以想象在其他可能的只有pull的端到端的设计，消费者会本地写到一个本地的日志中，然后broker会pull然后消费者会pull broker，通常会有一个“store-and-forward”的类似类型的生产者。这是有趣的但我们感觉不适用于我们的目标用例场景，这些场景有着成千的生产者。我们跑大规模的持久化数据系统的经验让我们感觉到跨越多个应用涉及到系统中成千的磁盘实际上并不会让事情变得更可靠，最后会变成运维的梦魇。在实践中我们同时发现在不需要生产者持久化的情况下依旧可以跑一个大规模并有着强SLA的流水线。

## 消费者位置

惊奇的是，记录哪些已经被消费了是消息系统中一个关键的性能点

大多数消息系统在broker上保留哪些消息已经被消费了的元数据，即，当消息传给消费者时，broker要不立即本地记录或等待消费者的ack。这是一个相当直觉的选择，且对于一个单一的服务器来说确实不清楚这个状态可以保存到其他哪里。因为许多消息系统使用的数据存储结构都是很难扩展的，这同时也是一个实用的选择——因为broker知道哪些已经被消费了，这样它可以立即删除它，保持小的数据大小

没那么显而易见的是让broker和消费者对哪些已经被消费了达成共识并不是一个简单的问题。如果broker在每次消息通过网络传出去的时候都记录消息是已经被消费了的话，如果消费者处理消息失败（比如因为它宕机了或者请求超时了或其他任何情况），那么消息就丢失了。为了解决这个问题，许多消息系统增加了ack的特性，这意味这消息只是被标记为sent而不是consumed当消息被发送时。这个策略解决了消息的丢失问题，但带了了新的问题。首先，如果消费者消费了消息但发送ack失败，那么消息会被消费两次。第二个问题是关于性能，现在对于每一个单一的消息broker必须维护多个状态（首先对它加锁这样它就不会发送两次， 然后标记它为永久被消费了的因此可以删除它），必须解决的棘手问题，比如怎么处理发送了但是从没被ack的消息。

Kafka处理的方式不同，我们的topic被分为完全有序的partition的集合，在任意是个每一partition都被每个订阅的消费者组中的恰好一个消费者消费。这意味着每个分区上消费者的位置只是一个整数，表示下一个要消费的消息的offset。这使得关于哪些已经被消费了的的状态很小，对于每个partition来说只是一个数字，这个状态可以被周期性地checkpoint，这使得响应的消息ack开销很小。

这个决定有个副作用，一个消费者可以故意地重置到一个老的offset然后重新消费数据。这破坏了队列的通用合同，但对许多消费者来说被证明是一个本质的特征。例如，如果消费者的代码出bug了，并且是在消费了许多消息后才发现的，那么消费者可以在修复bug后重新消费这些消息。

## 离线数据负载

可扩展的持久化让周期性的消费，比如周期性地批量装载数据到形如hadoop或关系型数据库的离线系统，这样的批量数据负载变得可能

In the case of Hadoop we parallelize the data load by splitting the load over individual map tasks, one for each node/topic/partition combination, allowing full parallelism in the loading. Hadoop provides the task management, and tasks which fail can restart without danger of duplicate data—they simply restart from their original position.

# 4.6 消息传递语义
既然我们对的生产者和消费者如何工作有了一点了解，让我们来讨论kafka提供的生产者和消费者之间的语义保证。清晰的是有着多种可能可以提供的消息传递语义
- At most once——消息可能丢失但永远不会重复投递
- At least once——消息永远不会丢失但可能会重复投递
- exactly once——这是人们想要的，消息不丢失且只会消费一次

值得注意的是这分解成两个问题：消息publish的持久性保障和消息消费的保障
许多系统声称提供exactly once的传递语义，但仔细阅读是重要的，许多这些声称都是有误导性的（即，它们不考虑消费者或生产者失败的情况，有着多个消费者进程的情况，写到磁盘中的数据可能会丢失的情况）

kafka的语义是很直接的，当public一个消息时我们有一个概念叫消息被commit到log里，一旦一个publish的消息被提交后，只要有一个复制了消息写到的分区的broker存活的话，消息就不会丢失。committed消息的定义，存活的分区以及关于我们尝试解决哪种类型的失败的描述将会在下一个章节进行详细描述。对与现在让我们假设有一个完美的不会丢失的broker，尝试来理解对生产者和消费者的保证。如果一个生长着尝试发布一个消息然后经历了一次网络错误，它不能确认错误是发生在消息committed之前还是之后。这类似于使用自动生成（auto-generated）的key插入到一个数据库表的语义

0.11.0.0之前，如果一个生产者接收消息commited的应答失败，除了重新发送消息外没有其他好的选择。这提供了at-least-once的传递语义，因为如果原来的请求成功了的话消息会被再次写入log。从0.11.0.0开始，kafka生产者也支持幂等的传递选项，保证了重新发送不会导致log中出现重复的项。为了实现这个，broker给每一个生产者指定一个ID然后通过使用生产者发送的每个消息都有的一个序列号来对消息进行去重。同样从0.11.0.0开始，生产者支持使用类似于事务的语义向多个topic分区发送消息：即，要不所有的消息都写入成功要不没有一个成功。这主要的应用场景就是kafka topics之间的exactly-once处理（后面会进行描述）

不是所有的用例场景都要求这么强的保证的，对于那些延迟敏感的用例来说我们允许生产者指定想要的持久性级别。如果生产者指定等待消息提交的时间，那么这可以在10ms的数量级上完成。然而生产者也可以指定它想要完全异步地发送消息（译注：）或者或者它可以只等到leader（但不用folllers）收到消息

现在让我们从消费者的视角来描述语义，所有的副本都有着相同的log以及相同的offset，消费者控制它在log中的位置。如果消费者永远都不会宕机那么它可以仅仅将位置保存在内存中，但如果消费者崩掉了然后我们想要这个topic分区被其他进程接管，那么新的进程需要选择一个合适的位置开始处理。让我们假设消费者读了一些消息——它有一些处理消息、更新位置的选项：
1. 它可以读取消息，然后将位置保存到日志上，最后处理消息，在这种情况下有可能消费者的进程在保存位置后但还没有将消息处理的输出保存下来就崩掉了。在这种情况下接管处理的进程会从保存的位置开始，即使此位置之前的一些消息还没有得到处理。这相当于“at-most-once"语义因为在消费者的情况下消息可能不能得到处理。
2. 它可以读取消息，处理消息，最后更新位置。在这种情况下有可能消费者进程在处理消息后崩掉了但是还没来得及保存位置，在这种情况下当新的进程接管时，它处理的一些新消息会是已经被处理过的。这在消费者失败的情况下符合“at-least-once"语义，许多场景中消息有一个主键因此更新是幂等的（接收相同的消息两次仅仅会用记录的另一个副本覆盖记录）

因此exactly once语义会是什么样的？当从kafka topic消费时以及生产消息到其他topic，我们可以权衡上面提到的0.11.0.0引入的新事务型生产者能力。消费者的位置保存为topic的一个消息，因此我们可以在同一个事务中写offset到kafka上，正如输出topic接收处理过的数据。如果事务被中断了，消费者的位置会回滚到旧值，输出topic上生产出的数据将不会对其他消费者可见，取决于他们的隔离级别。在默认的read_uncommitted隔离级别中，所有的消息都对consumer可见及时它们是一个中断了的事务的一部分，但在read_committed中，消费者只会返回一个提交了的事务的消息（以及任何不从属于事务的消息）

当写到外部系统上时，限制就是需要和那些实际存储为输出来协调消费者的位置。最经典的实现方式在存储消费者位置的存储系统和存储消费者输出的存储系统间引入两阶段提交 。但这可以使用更简单更通用的方式来解决，即通过让消费者将输出和offset存储在相同的地方。这个方案更好因为许多消费者想要写入的输出系统不支持两节点提交。例如，考虑一个[Kafka Connect](https://kafka.apache.org/documentation/#connect)连接器，它将数据以及读取的数据的offset一起导入到HDFS中这样就能保证数据和offset就能同时被更新。对于其他的数据系统我们遵循类似的模式，这些系统要求这些更强的语义并且消息没有一个主键来去重

在[Kafka Streams](https://kafka.apache.org/documentation/streams)中kafka很高效地支持了exactly-once传递，事务型生产者和消费者可以被很广泛地使用来在kafka topics之间传输和处理数据时提供exactly-once传递。对于其他目标系统来说，exactly-once传递需要和这些系统协调，但kafka提供了offset使得实现变得可行（参见[Kafka Connect](https://kafka.apache.org/documentation/#connect))。另外，kafka默认保证at-least-once传递，允许用户实现at-most-once传递，通过禁止producer的重试以及消费者上在处理批量消息之前先提交offset

# 4.7 复制
Kafka在可配置数量的服务器上复制每个topic分区的日志（你可以在topic的级别上设置这个复制因子），这允许了当集群中一个服务器失败时对这些副本进行自动的故障恢复（failover）因此消息在节点失败的情况下保持可用

其他消息系统提供一些复制相关的特性，但是，在我们看来（完全有偏见的），这好像是硬塞进去的，不被重度使用，并且有着很大的缺点：slaves是不活却的，吞吐量被严重影响了，还要求精妙地手工配置，等等。kafa默认就是会使用复制——实际上当复制因子为1时我们实现了非复制的topic

复制的单位是topic分区。在没有失败的条件下，kafka中每个分区有一个leader以及0个或更多的follower。副本的总数包括leader在内就是复制因子。所有的读和写都流向分区的leader，典型情况下， partition的数量比broker更多，leader均匀地分布在broker上。follower上的log和leader的log是相同的——都有着相同的offset和相同顺序的消息（尽管，当然，在任意给定时间leader在其log尾部可能有一些还未复制的消息

follower像一个正常的kafka消费者一样从leader处消费消息，然后将消息放入自己的log中。让follower从leader上pull有一个很棒的属性，即允许follower自然地将要追加的日志项batch在一起

正如大多数分布式系统，自动处理故障需要对节点存活意味着什么有着准确的定义，对于kafka节点而言，存活性有着两个条件
1. 节点必须能够保持和zookeeper的会话（通过zookeeper的心跳机制）
2. 如果节点是一个slave那么它必须复制leader上发生的写，并且不要落后太远

我们将满足这两个条件的节点称作是同步的来避免称作存活或失败的含糊性。leader跟踪同步的节点集合，如果一个follower死掉了、卡住了或落后了，leader会将它从同步的副本列表中移除。stuck的定义和延后的副本可由replia.lag.time.max.ms配置控制

在分布式系统术语中我们只尝试处理失败的失败/恢复模型，模型中节点突然停止工作然后稍后恢复（可能不知道它们死过了）。Kafka不处理所谓的拜占庭失败，在这种情况下节点可能发出任意的或带有欺骗性的恢复（可能因为bug或者不正当的行为）

我们现在更准确地进行定义，当分区的同步副本集中所有节点都将消息追加到它们log中时，消息就被认为是committed的。只有committed的消息会被传给消费者。这意味着消费者不需要担心可能会看到一个由于leader失败可能丢失了的消息。生产者，另一方面，有选项决定是等到消息被committed还是不等，取决于它们对延迟和持久性的权衡的偏好，这种偏好由生产者使用的ack设置控制。注意topic有一个同步副本集的最小数目的设置（译注：类似于majority），当生产者要求消息被写到同步副本集的所有节点的ack时会检查这个数目。如果生产者要求一个不那么严格的确认时，即使同步副本集中的数量低于minimum时，消息依旧可以被committed被消费

kafka提供的保证是一个committed的消息不会丢失，只要在所有时间上同步副本集中至少有一个节点存活

kafka在节点失败然后一个短的故障恢复时期后依旧保持可用，但在网络分区的情况下可能不会保持可用

## 复制的日志：法定人数，ISR，和状态机（word天）
kafka分区的核心是复制的日志，复制的日志是分布式数据系统中最基本的原语之一，有很多方法能够实现。在[状态机风格](http://en.wikipedia.org/wiki/State_machine_replication)中一个复制的日志可以被其他系统以原语的方式使用来实现其他的分布式系统

一个复制日志模型对在一系列的值的顺序上达成共识进行建模（通常来说给日志项编号为0,1,2,...)。有很多方式实现这个，但最简单也是最快的是有一个leader来决定提供给它的值的顺序。只要leader保持存活，其他follower仅需要复制值然后按leader选择的顺序对它们进行排序

当然如果leader不失败的话我们甚至不需要follower！当leader真的死掉后我们需要在follower中选出一个新leader，但follower自身可能会落后或者是宕机因此我们必须确保我们选择一个最新的follower。一个日志复制算法必须提供的最基本的保证就是如果我们告诉客户一个消息被committed了，然后leader失败了，我们选出的新leader必须也有这条消息。这可以有个权衡：如果leader在将一个消息声明为committed之前等待更多follower来ack消息，那么会有更多潜在的合格的leader

如果你选择选举一个leader要求的ack的数量以及必须比较的log数目，这样来保证不会有重叠，那么这就叫做法定人数


这个权衡一个常见的方法就是对commit决定以及leader选举使用多数派投票。这不是kafka用的，但不管怎样让我们探索它来理解权衡。假设我们有2f+1个副本，如果在leader声称一个消息是commit之前f+1个副本必须先收到消息，然后我们通过在f+1个副本中选取有最完整的日志的follower来选取leader，那么只要不超过f个节点失败，leader能保证有着所有committed的消息。这是因为在f+1个副本中，至少有一个副本有着所有committed的消息，这个副本日志是最完整的因此会被选为新的leader。还有更多遗留的每个算法都必须处理的细节（比如准确定义什么让一个日志更完整，在leader失败时确保日志的一致性，或者改变副本集中的服务器集合）但目前我们将忽略这些

多数派选举有着一个很好的属性：延迟只取决于最快的那些服务器，即，如果复制因子是3，延迟由快的slave决定而不是慢的那个

这个家族由很多算法，包括zookeeper的zab、raft、viewstamped replication。和kafka实际实现最相近的学术出版是微软的pacificA

多数派选举的缺点是不需要太多失败就能让你没有有候选资格的leader。为了容忍一个失败需要数据的三个拷贝，为了容忍两个失败需要数据的五个拷贝。在我们的经验中为了容忍单点故障而创建足够的冗余对于实际的系统来说是不够的，只是每次都写五次，需要五倍的磁盘空间要求和1/5的吞吐量，对于海量数据问题来说不是很实际的。这可能是为什么法定人数算法更常见于共享集群配置比如zookeeper而不常见于原始数据存储。例如在HDFS中namenode的高可用性特性是用[基于多数派投票的日志](http://blog.cloudera.com/blog/2012/10/quorum-based-journaling-in-cdh4-1)构建的，而这种更昂贵的方法并没有用于数据本身

kafka采取了稍微不同的方法来选择它的法定人数集合。不是用多数派投票，kafka动态地维护一个紧跟leader的同步副本集(ISR)。只有这个集合的成员有资格被选为leader。一个kafka分区的写直到同步副本集中所有节点都收到写之后才被认为是committed的，这个ISR集合被持久化到zookeeper上每当它发生改变时。因此，ISR中的所有副本都被认为是有资格成为leader的。这对有着很多分区并且确保领导权平衡是重要的的kafka使用模型来说是一个关键的因素。有着这个ISR模型以及f+1个副本，一个kafka topic能够容忍f个失败并且不会丢失committed的消息

对于我们希望处理的大多数用户场景来说，我们认为这个权衡是合理的。在实践中，为了容忍f个失败，多数派选举和ISR方法都会等待相同数量的副本的ack来commit一个消息（比如，为了容忍一个失败多数派法定人数需要三个副本和一个ack,ISR方法需要两个副本和1个ack）。commit不用考虑最慢的服务器的能力是多数派投票的一个优点。然而，我们认为这点可以通过让客户选择它们是否等待消息commit得到减轻，因更低要求的复制因子从而得到的附加的吞吐量和磁盘空间值得一试

另外一个重要的设计区分就是kafka不要求宕机的节点恢复时数据都是完整的。在这个空间中，依赖于在任何故障恢复场景下、没有违背潜在的一致性不会丢失的可靠存储的存在的复制算法并不少见。这种假设有两个主要的问题，首先，在我们对持久化数据系统的实际操作的观察中，磁盘错误是最常见的问题，它们通常不会使得数据保持完整，其次，即使这不是个问题，我们不想要为了我们的一致性保障而每次写都要使用fsync，因为着可能会以二个或三个数量级地降低性能。我们允许一个副本重新加入ISR的协议确保在重新加入之前，它必须完全地重新进行同步尽管它可能在宕机时丢失了未刷盘的数据

## 不干净的leader选举：如果它们都挂了呢
注意kafka和数据丢失相关的保证是基于至少有一个副本保持同步的，如果复制一个分区的所有节点都挂了，这个保证不能继续维持

然而一个实际的系统在所有的副本都挂掉的时候需要做一些合理的事。如果你不幸运，这发生了，考虑将会发生什么是很重要的，有两种可以被实现的行为：
1. 等待ISR中的一个副本恢复，选择这个副本作为leader（希望它仍然还有它所有的数据）
2. 选择第一个副本（不一定是在ISR中的）恢复然后选它做leader

这是对可用性和一致性的一个简单权衡，如果我们等待ISR中的副本，那么只要这些副本是宕机中的，我们就会保持不可用。如果这些副本被destroy了或者它们的数据丢失了，那么我们会永久地宕机。如果，从另一方面，一个不处于同步状态的副本恢复了，然后我们允许它成为leader，那么它的日志变成真理的来源尽管它不能保证拥有所有committed的消息。默认情况下，kafka选择第二种策略，支持选择一个潜在不一致的副本当ISR种所有的副本都挂掉时。这个行为可以被禁止通过使用配置属性unclean.leader.election.enable，来支持当宕机时间相比于不一致性更能被容忍的用例场景

这个困境不专属于kafka，在任何基于法定人数的方案种存在。例如在多数派投票的方案种，如果大多数server都永久宕机了，那么你必须在丢失100%的数据或者是因选择剩余的server作为真理的来源而导致破坏一致性之间进行选择

## 可用性和持久性保证
当向kafka种写数据时，生产者可以选择它们是否等待消息被0、1或all(-1)个副本ack，注意“被所有的副本ack不能保证指定的副本的全集都收到了消息”。默认，当acks=all时，只要所有当前的同步副本都收到了消息就可以ack了。例如，如果一个topic被配置为只有两个副本，然后其中一个宕机了（即，同步副本种只有一个存活），那么指定了acks=all的写将会成功。然而，如果剩下的副本也宕机了，那么写将会丢失。尽管这确保了分区的最大可用性，这个行为可能对一些更想要持久性而不是一致性的用户来说是不可接受的。因此，我们提供了topic层面的配置，可以被用来更偏向于持久性而不是一致性:
1. 禁止不干净的leader选举——如果所有的副本都不可用了，那么分区会保持不可用直到最新的leader再次变得可用。这有效地更偏好于不可用而不是消息丢失的风险，查看前面不干净的leader选举
2. 指定最小ISR大小——分区只有在ISR里副本个数在minimum之上才会接受写，以避免消息只写入一个副本，副本随后变得不可用，从而造成的消息丢失。这个设置提供了一个一致性和可用性之间的权衡，设置最小ISR大小更高能保证更好的一致性，因为消息能确保写入更多的副本，这减少了丢失的可能性。然而，降低了可用性因为分区将会变得对写不可用如果同步副本数降低到最小阙值之下


## 副本管理
上面关于复制的日志的讨论覆盖了单一的log，即，一个topic分区。但一个kafka集群将会管理成百上千这样的分区。我们尝试在寄存中使用round-robin的风格来均衡分区，以避免将大数据量的topic的所有分区都聚集到少数节点上。同样我们尝试平衡领导权这样每一个节点是它拥有的分区的一部分的leader

这对优化领导权选举进程呢也是很重要的因为。一个leader选举的简单实现最后会在一个节点挂掉时节点的持有的所有分区中每一个分区都要进行一个选举。相反，我们选择一个broker作为controller。这个controller检测broker层面的是啊比，对改变一个宕机的broker上所有受影响的分区的leader负责。结果就是我们能对将许多需要的领导权改变的通知批量起来，这使得对于大量的分区而言选举过程更加廉价、快速，如果controller挂掉了，剩余的一个broker会变成新的controller

# 4.8 日志压缩
日志压缩确保kafka始终会对每一个消息的key保留最新知道的值在单一的topic分区的很多数据之内。这着眼于一些比如在应用崩溃之后或系统失败之后重新恢复状态、或者在系统因运行维护重启之后重新导入缓存的应用场景。让我们更深入地了解这些应用场景然后描述压缩是怎么工作的

目前位置我们已经描述了最简单的数据保留的方式，在这种方式中老的日志数据在过固定时间周期后或当日志达到某些预先定义的大小后被丢弃。对于临时时间数据比如每一个记录都独立存在的日志而言这工作得很好，然而一类重要的数据流是有主键的、可变的数据的改变的日志（比如，一个数据库表的改变）

让我们讨论这种流的一个具体实例。假设我们有一个topic其中包括了用户邮件地址；每一次一个用户更新他的邮件地址时我们就发送一个消息到topic上，使用用户id作为主键。现在假设我们在一定时间期间内给一个userid为123的用户发送如下消息，每一个消息和邮箱地址的一个改变相关（其他用户id的消息忽略）：

    1    123 => bill@microsoft.com
    2            .
    3            .
    4            .
    5    123 => bill@gatesfoundation.org
    6            .
    7            .
    8            .
    9    123 => bill@gmail.com

日志压缩提供给我们一个更粒度的保留机制这样我们保证能至少保留每个主键最新的更新（比如， bill@gmail.com)。这样做我们保证日志包含了每一个key最后的值的完整快照，而不仅仅只有最近改变的key。这意味这下流消费者不需要我们保留所有改变的完整日志就能恢复它们在这个topic上的状态

让我们以看一些这个特性是有用的用力场景，然后我们将会知道它是怎么被使用的
1. 数据库改变订阅。通常在多个数据系统拥有一个数据集是必要的，并且通常这些系统其中一个就是某种数据库（或者是关系型数据库或者是新型的kv存储）。例如你可能有一个数据库、一个缓存、一个搜索集群还有一个hadoop集群。数据库的每个改变都需要反映到缓存、搜索集群，最后到hadoop。在这种情况下住处离实时更新的话你只需要最近的日志，但如果你想要能重载缓存或者恢复一个失败的搜索节点的话你可能需要一个完整的数据集。
2. 事件来源。这是一种应用的设计风格，其将查询处理和应用设计联系起来，并使用记录改变的日志作为应用的主要存储
3. 高可用性的日志。一个做本地计算的进程可以，通过将它对本地状态的改变记录下来，从而变成故障容忍的，这样其他进程可以在它挂掉的时候重载这些改变然后继续运行。一个具体的例子就是在一个流式查询系统中处理技术、聚合还有其他类似于“group by”的处理。Samza，一个实时流处理框架，[使用这个特性](http://samza.apache.org/learn/documentation/0.7.0/container/state-management.html)恰好是为了这个目的


在每一种情况下主要处理改变的实时反馈，但偶尔，在机器宕机或者数据需要被重新加载或重新处理的时候，我们需要进行一个完整的装载。日志压缩允许这两种使用场景都从相同的topic中获取数据。这种对日志的用法风格在[这篇博客](http://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying)中有更详细的描述

总体思想是很简单的，如果我们有无限的日志保留，然后我们在以上的场景中记录每一个改变，那么我们能捕获从系统第一次运行后任意时间点上的系统状态。使用这个完整的日志，我们可以恢复到任意时间点，通过重放日志中前N个记录。这个假设的完整日志对一个更新一个记录很多次的系统来说并不实际，因为日志会无线地增长，即使是对一个稳定的数据集来说。简单的日志保留机制，将旧的更新抛弃的，可以限制空间但是日志不再是一个能恢复当前状态的方式——现在从日志开始进行恢复不能再重新创建当前状态，因为老的更新可能根本没有被捕获

日志压缩是一个给予更细粒度的每个日志的保留机制，而不是粗粒度的基于时间的保留。思想就是选择性地移除日志，这些日志的主键有着更新的更新，这样日志能保证对于每个key至少有最近的状态

保留策略可以是设置在topic级别的，这样一个单一集群可以有一些topic的保留机制是通过大小或时间执行的，另外一些topic的保留机制是通过压缩进行的。

这个功能由领英最老的也是最成功的基础组件的一部分——一个数据库changelog缓存服务，叫[Databus](https://github.com/linkedin/databus)启发而来。和大多数日志结构的存储系统不一样的是kafka是为了订阅构建的，为了快速线性读写而组织数据。和Databus不一样，kafka充当一个真理的来源（source-of-truth）存储，因此这是有用的即使在上流数据源不可重放的情况

## 日志压缩基础
这里有个展现了额kafka日志的逻辑结构的高层次的图，每一个消息都有offset
![](/img/kafka_log.png)

日志的首部和一个传统的kafka日志一样，它有着紧密的、连续的offset并保留了所有的消息。日志压缩给处理日志的尾部增加了一个选项。上面的图展示了一个有着压缩尾部的日志，注意到日志尾部的消息保留了原始指定的在它们第一次写入时的offset——这从不改变。同时注意所有的offset保持在日志中的合法位置，尽管有这个offset的消息已经被压缩掉了；在这种情况下这个位置对日志中出现的下一个最高的offset来说是不可辨认的。比如，上图中offset 36、37、38都是相同的位置，一个从这些offset中任意一个开始的读都会返回从38开始的消息集合

压缩同样允许删除，一个有key和空负载的消息会被认为是日志的一个删除。这个删除标记会使得这key的先前消息被一处（同样这key新的消息也会被一处），但删除标记是特殊的，它们自己会在一段时间过后从日志中清空出去以释放空间。删除（标记）不在被北流的时间点在上图中被标记为"delete retention point"

压缩通过在后台周期性地重新拷贝日志片段完成，清理不会阻塞读同时可以被限流为使用不超过一个可配置的IO吞吐量，以避免影响生产者和消费者。压缩一个日志片段的实际过程类似于这样：
![](/img/kafka_log_compaction.png)

## 日志压缩提供哪些保证
日志压缩有下列保证：
1. 任何保持跟进在log头部的消费者会看到每一个新写入的消息；这些消息有着连续的offset。topic的min.compaction.lag.ms可以用来保证消息写入到可以被压缩的需要经过的最短时间，即，它提供了每个消息保留在（非压缩）头部的时间的下界
2. 消息的排序总是得以保持。压缩不会重新排序消息，只是移除了一些而已
3. 消息的offset从不改变，是日志中一个位置的永久标志
4. 任何从日志开始处开始处理的消费者会者少看到所有记录的最后状态，以它们被写入的顺序。另外，所有的删除了的日志的删除标记会被看到，假如消费者在小于topic的delete.retention.ms设置（默认24小时）的时间内到达了日志的头部。换句话说：因为删除标记的移除和都操作同步发生，对于一个消费者来说可能会错过删除标记如果它延迟的时间超过delete.retention.ms

## 日志压缩细节
日志压缩由log cleaner处理，log cleaner是一些后台线程的线程池，这些线程重新拷贝日志片段文件，删除那些key出现在日志头部的记录，每一个压缩（compactor）线程像下面这样工作：
1. 它选择有着最高log head/log tail比例的日志
2. 它创建log head中每一个key的最后一个offset的简明概要
3. 它从开头到结尾重新拷贝日志，删除那些又在后面出现过的key。现在，干净的片段被马上换入log中，因此额外的磁盘空间要求只是一个额外的log片段（不是日志的完整拷贝）
4. 日志头部的概要本质来说只是一个空间紧凑的哈希表，每一个项恰好使用24字节，结果就是有着一个8GB的cleaner缓存，一次cleaner迭代可以清理大约366GB的日志头部（假设1k个消息）（？？）

## 配置log cleaner
log cleaner默认是开启的，这会启动cleaner进程池，为了启用一个特定topic的日志清理你可以加上下面的针对log的属性

    log.cleanup.policy=compact

这可以在topic创建的时候完成，或者使用改变topic的命令

log cleaner可以被配置为保留最小数量的未压缩的日志头部，这个可以通过设置压缩压缩延迟时间启用
    
    log.cleaner.min.compaction.lag.ms
    
这可以防止新于最小消息年龄的消息被压缩。如果没有设置，除了最后一个片段（即当前正在写入的）外所有的日志片段都是可以被压缩的。活跃的片段不会被压缩即使它所有的消息都老于最小的压缩时间延迟

更深入的cleaner配置在[这里](http://kafka.apache.org/documentation.html#brokerconfigs)有描述

# 4.9 配额
kafka集群有给请求施加配额的能力，来控制broker被client使用的资源。两种类型client定额可以被kafka实施，针对每一个共享着一个定额的client组
1. 网络带宽定额定义了字节速率阙值（从0.9版本开始）
2. 请求速率定额定义了CPU使用率阙值为网络和IO线程的比例（从0.11版本开始）

## 为什么配额是必要的
对于生产者和消费者来说可能会生产/消费巨量的数据或者是以非常高的速率发起请求，因此独占了broker资源，导致网络饱和，通常DOS了其他client和broker自身。有了配额就可以防止这些问题，并且对于大型的多租户集群，有着一小部分的表现异常的client可以降低那些表现良好的client的使用体验，这愈加重要。实际上，当将kafka作为服务运行时，这使得根据合约限制实施API限制变得可能。

## client组
kafka clients的标志是用户主体(user principal)，代表了在一个安全的集群中验证过的用户。在支持未验证client的集群里，用户主题就是一组由broker使用一个可配置的PrincpalBuilder选择的一组未验证的用户。cilent-id是clients的一个逻辑分组，带有一个client应用程序选择的有意义的名字(name)，元组(user，client-id)定义了一个安全的clients的逻辑组，其中client共享相同的用户主体和client-id

配额可以被应用到(user，cilent-id)，用户或client-id组。对于一个给定的连接来说，匹配连接的最确切的定额会被应用。一个组的所有连接共享为这个组配置的配额。例如，如果（user="test-user",client-id="test-client"）有一个生产配额为10MB/秒，这将会被client-id为test-client的test-user用户的所有生产者实例共享

## 配额配置
配额配置可以为(user,client-id)、user和client-id组定义，可以在任意的需要更高或更低配额的配额层次覆盖默认的配额。这个机制类似于per-topic日志配置覆盖。user和(user,client-id)配额的覆盖被写到zookeeper的/config/users下，client-id配额的覆盖被写到/config/clients下。这些覆盖被所有的broker读取，即时生效。这让我们不用依次重启整个集群就能改变配额，查看[这里](http://kafka.apache.org/documentation.html#quotas)了解更多细节。每个组的默认配额也可以使用相同的机制动态更新

配额配置的优先顺序为：
1. /config/users/<user>/clients/<client-id>
2. /config/users/<user>/clients/<default>
3. /config/users/<user>
4. /config/users/<default>/clients/<client-id>
5. /config/users/<default>/clients/<default>
6. /config/users/<default>
7. /config/clients/<client-id>
8. /config/clients/<default>

broker属性（quota.producer.default，quota.consumer.default）也可以被用来设置client-id组默认的网络带宽，这些属性是不被建议的，将会在之后的发布中移除，client-id的默认配额可以在zookeeper中设置，类似于其他配额覆盖或默认

## 网络带宽配额
网络带宽配额被定义为对每个共享一个配额的client组的字节速率阙值。默认，每个client组接受集群配置的以bytes.sec为单位的固定配额，这个配额是在每个broker上定义的，每组的cilent可以发布/接受最大为X bytes/sec各broker，在client被限流之前(??)

## 请求速率配额
请求速率配额被定义为一个client在一个定额窗口内可以使用各broker的请求处理IO线程和网络线程的时间比例，定额为n%表示一个线程的n%，因此定额的总容量为todo，每一个client组可以在一个配额窗口内使用比例上限为n%的所有io和网络线程。因为为io和网络分配的线程数量一般是基于broker上的cpu核数，请求速率配代表了共享配额的client组，可以使用的cpu时间比例

## 实施
默认，每个独特的client组接受cluster配置的固定配额，这个配额是在各broker基础上定义的，每个client可以在被限流之前在各broker上使用这个配额。我们决定在各broker上定义这些配额比一个集群范围内各client的固定的网络带宽要来的好，因为这要求一个在所有的broker之间共享客户对配额的使用的机制，这可以比实现配额自身要难得多

在broker检测到有违背配额时，它会怎么做？在我们的解决方案中，broker不返回error而是会尝试减慢一个超出定额的client，它计算所需的延迟来让一个犯错了的client降回其配额之下，会在那段时间内延迟回复。这个方法使得配额违背对client透明（在client端的度量之外）.这也可以让它们不用实现任何专门的回退或者重试行为，而这些行为实现起来可能会变得困难。实际上，坏的客户端行为（没有回退的重试）可以恶化正在解决的有问题的配额

字节速率和线程使用是在多个小窗口（比如，30个1s的窗口）内度量的，来迅速地检测和修正配额违背。一般来说，大的度量窗口（比如，10个30秒的窗口）会导致流量高峰后尾随着长时间段的延迟（large bursts of traffic followed by long delays)，而这从用户体验来说并不好

